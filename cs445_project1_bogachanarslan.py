# -*- coding: utf-8 -*-
"""CS445-Project1-bogachanarslan

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13t32YKD6T4PSNeRw71UoS_SySUN-5Gtf
"""

# Run this cell to mount your drive to this notebook in order to read the datasets
from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np

import warnings
warnings.filterwarnings("ignore")

"""## Read Dataset"""

# Put the folder path where the datasets are located
PATH = "/content/drive/MyDrive/445project1/"

cd /content/drive/MyDrive/445project1/

# Read the train and test set with read_csv() method of pandas
train = pd.read_csv(PATH + "train.csv")
test = pd.read_csv(PATH + "test.csv")

print(train.shape)
print(test.shape)

train.head(10)

"""### Preprocess Dataset"""

import re
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer

nltk.download('punkt')



# Define a function to perform preprocessing. This function can perform things like lowercasing, stemming, removing stopwords, etc.

import string
ps = PorterStemmer()
#s_tokenizer = nltk.tokenize.punkt.PunktSentenceTokenizer()
w_tokenizer = nltk.tokenize.WordPunctTokenizer()
stops = set(stopwords.words('english'))

def preprocess(text: str):
    #sentences = nltk.sent_tokenize(text)
    text = text.lower()
    words = w_tokenizer.tokenize(text)
    res = ""
    for w in words:
      if w not in stops and [x for x in w if string.punctuation.find(x) != -1] == []:
        res += ps.stem(w) + " "
    #print(res)
    return res

# Apply your preprocessing function to your text fields.

train.text = train.text.apply(preprocess)
test.text = test.text.apply(preprocess)

train.shape, test.shape
#print(train.text)

test.head(20)

print(type(train["text"][0]))

# Create your binary and multiclass datasets

# For binary dataset, get rid of the class 3 in the dataset and map class 1 and 2 to 0, and class 4 and 5 to 1
binary_train = train.copy(deep=True)
binary_test = test.copy(deep=True)

binary_train = binary_train[binary_train.label != 3]
binary_train.loc[binary_train.label <= 2,['label']] = 0
binary_train.loc[binary_train.label >= 4,['label']] = 1

binary_test = binary_test[binary_test.label != 3]
binary_test.loc[binary_test.label <= 2,['label']] = 0
binary_test.loc[binary_test.label >= 4,['label']] = 1


# For multiclass dataset, make sure your classes starts from 0 and goes until 4. (5->4, 4->3, 3->2, 2->1, 1->0)

multi_tr = train.copy(deep=True)
multi_ts = test.copy(deep=True)

multi_tr.label -= 1
multi_ts.label -= 1

#multi_tr.head(5)
multi_tr.head(20)

binary_train_text = binary_train["text"].values
binary_train_labels = binary_train["label"].values

multi_train_text = multi_tr["text"].values
multi_train_labels = multi_tr["label"].values

binary_test_text = binary_test["text"].values
binary_test_labels = binary_test["label"].values

multi_test_text = multi_ts["text"].values
multi_test_labels = multi_ts["label"].values

"""# Models

## Non-Neural Models
"""

from sklearn.model_selection import GridSearchCV
from sklearn.base import TransformerMixin
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import f1_score,confusion_matrix,accuracy_score

"""### Naive Bayes"""

# https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html

# Create a class for converting sparse matrix output of TfidfVectorizer to dense matrix for feeding into GaussianNB
class DenseTransformer(TransformerMixin):

    def fit(self, X, y=None, **fit_params):
      '''
      tfid = TfidfVectorizer(**fit_params)
      vec = tfid.fit(X)
      return vec
      '''
      return self

    def transform(self, X, y=None, **fit_params):
      #sparse = self.fit(X,**fit_params).transform(X)
      return X.todense()


# Initiate the pipeline with required components.You can use Pipeline class of sklearn -> https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html
# There will be three components; 1) TfidfVectorizer 2) DenseTransformer 3) Naive Bayes classifier.
pipeline = Pipeline([
                     ("vectorizer",TfidfVectorizer()),
                     ("transformer", DenseTransformer()),
                     ("nb_classifier", GaussianNB())
])


# Set the hyperparameter space that will be scanned with GridSearchCV.
search_params = {
    "vectorizer__min_df": (100,500,1000),
    "vectorizer__ngram_range": ((1,1),(1,2),(1,3))
}

"""### Binary"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# 
# # Initialize and run the GridSearchCV to scan the hyperparameter and find the best hyperparameter set that will maximize the scoring option for binary classification.
# grid = GridSearchCV(pipeline, search_params, scoring = 'f1_macro', return_train_score= False, verbose = 1)
# grid.fit(binary_train_text, binary_train_labels)
# # Report the standart deviation of split scores for each hyperparameter group.
# 
# for i in range(9):
#   print("STD for trial ",i,":\n",grid.cv_results_["params"][i]," - ",grid.cv_results_["std_test_score"][i] ,sep="")
# 
# # Show the best parameter set for given dataset and hyperparameter space.
# print("Top parameters & score: \n", grid.best_params_, " - ", grid.best_score_ ,sep ="")
# 
# 
#

# Building the pipeline with the best parameter group and reporting Conf. Mat. and Results on the Test Set #
# Create your Pipeline object with the best parameter set.
pipeline_top = Pipeline([
                     ("vectorizer",TfidfVectorizer(min_df=100, ngram_range = (1,3))),
                     ("transformer", DenseTransformer()),
                     ("nb_classifier", GaussianNB())
])

# Fit your pipeline on training set.
pipeline_top.fit(binary_train_text, binary_train_labels)

# Take prediction and report the F1 and Accuracy scores for binary classification. Then show the confussion table.
pred_res = pipeline_top.predict(binary_test_text)
acc = accuracy_score(binary_test_labels, pred_res)
f1 = f1_score(binary_test_labels, pred_res, average="macro")
conf_matrix = confusion_matrix(binary_test_labels, pred_res)
print("Accuracy score:", acc)
print("F1 score:",f1)

#TODO Seaborn confusion matrix draw

"""### Multi"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# # Initialize and run the GridSearchCV to scan the hyperparameter and find the best hyperparameter set that will maximize the scoring option for multiclass classification.
# 
# 
# # Initialize and run the GridSearchCV to scan the hyperparameter and find the best hyperparameter set that will maximize the scoring option for binary classification.
# grid_m = GridSearchCV(pipeline, search_params, scoring = 'f1_macro', return_train_score= False, verbose = 1)
# grid_m.fit(multi_train_text, multi_train_labels)
# # Report the standart deviation of split scores for each hyperparameter group.
# 
# for i in range(9):
#   print("STD for trial ",i,":\n",grid_m.cv_results_["params"][i]," - ",grid_m.cv_results_["std_test_score"][i] ,sep="")
# 
# # Show the best parameter set for given dataset and hyperparameter space.
# print("Top parameters & score: \n", grid_m.best_params_, " - ", grid_m.best_score_ ,sep ="")
#

pipeline_top = Pipeline([
                     ("vectorizer",TfidfVectorizer(min_df=100, ngram_range = (1,2))),
                     ("transformer", DenseTransformer()),
                     ("nb_classifier", GaussianNB())
])

# Fit your pipeline on training set.
pipeline_top.fit(multi_train_text, multi_train_labels)

# Take prediction and report the F1 and Accuracy scores for binary classification. Then show the confussion table.
pred_res = pipeline_top.predict(multi_test_text)
acc = accuracy_score(multi_test_labels, pred_res)
f1 = f1_score(multi_test_labels, pred_res, average="macro")
conf_matrix = confusion_matrix(multi_test_labels, pred_res)
print("Accuracy score:", acc)
print("F1 score:",f1)

#TODO Seaborn confusion matrix draw

"""### Logistic Regression"""

# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html

# Initiate the pipeline with required components.You can use Pipeline class of sklearn -> https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html
# There will be three components; 1) Word weightning 2) Logistic Regression classifier.

pipeline = Pipeline([
                     ("vectorizer",TfidfVectorizer()),
                     ("logistic_classifier", LogisticRegression(random_state=22, penalty="elasticnet", solver = "saga"))
])

# Set the hyperparameter space that will be scanned with GridSearchCV.
search_params = {
    "vectorizer__min_df": (100,500,1000),
    "vectorizer__ngram_range": ((1,1),(1,2),(1,3)),
    "logistic_classifier__l1_ratio": (0.0,0.5,1.0)
}

"""#### Binary"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # Initialize and run the GridSearchCV to scan the hyperparameter and find the best hyperparameter set that will maximize the scoring option for binary classification.
# grid = GridSearchCV(pipeline, search_params, scoring = 'f1_macro', return_train_score= False, verbose = 1)
# grid.fit(binary_train_text, binary_train_labels)
# # Report the standart deviation of split scores for each hyperparameter group.
# 
# for i in range(9):
#   print("STD for trial ",i,":\n",grid.cv_results_["params"][i]," - ",grid.cv_results_["std_test_score"][i] ,sep="")
# 
# # Show the best parameter set for given dataset and hyperparameter space.
# print("Top parameters & score: \n", grid.best_params_, " - ", grid.best_score_ ,sep ="")
# 
# 
# 
#

# Building the pipeline with the best parameter group and reporting Conf. Mat. and Results on the Test Set #
# Create your Pipeline object with the best parameter set.
pipeline_top = Pipeline([
                     ("vectorizer",TfidfVectorizer(min_df=100, ngram_range = (1,2))),
                     ("logistic_classifier", LogisticRegression(random_state=22, penalty="elasticnet", solver = "saga", l1_ratio = 0.5))
])

# Fit your pipeline on training set.
pipeline_top.fit(binary_train_text, binary_train_labels)

# Take prediction and report the F1 and Accuracy scores for binary classification. Then show the confussion table.
pred_res = pipeline_top.predict(binary_test_text)
acc = accuracy_score(binary_test_labels, pred_res)
f1 = f1_score(binary_test_labels, pred_res, average="macro")
conf_matrix = confusion_matrix(binary_test_labels, pred_res)
print("Accuracy score:", acc)
print("F1 score:",f1)

#TODO Seaborn confusion matrix draw

"""#### Multiclass"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # Initialize and run the GridSearchCV to scan the hyperparameter and find the best hyperparameter set that will maximize the scoring option for binary classification.
# grid_m = GridSearchCV(pipeline, search_params, scoring = 'f1_macro', return_train_score= False, verbose = 1)
# grid_m.fit(multi_train_text, multi_train_labels)
# # Report the standart deviation of split scores for each hyperparameter group.
# 
# for i in range(9):
#   print("STD for trial ",i,":\n",grid_m.cv_results_["params"][i]," - ",grid_m.cv_results_["std_test_score"][i] ,sep="")
# 
# # Show the best parameter set for given dataset and hyperparameter space.
# print("Top parameters & score: \n", grid_m.best_params_, " - ", grid_m.best_score_ ,sep ="")
#

pipeline_top = Pipeline([
                     ("vectorizer",TfidfVectorizer(min_df=100, ngram_range = (1,3))),
                     ("logistic_classifier", LogisticRegression(random_state=22, penalty="elasticnet", solver = "saga", l1_ratio=0.5))
])

# Fit your pipeline on training set.
pipeline_top.fit(multi_train_text, multi_train_labels)

# Take prediction and report the F1 and Accuracy scores for binary classification. Then show the confussion table.
pred_res = pipeline_top.predict(multi_test_text)
acc = accuracy_score(multi_test_labels, pred_res)
f1 = f1_score(multi_test_labels, pred_res, average="macro")
conf_matrix = confusion_matrix(multi_test_labels, pred_res)
print("Accuracy score:", acc)
print("F1 score:",f1)

#TODO Seaborn confusion matrix draw

"""## Neural Models

### Convolutional Neural Network (CNN) Data Setup
"""

import pandas as pd
import numpy as np
import nltk,re
import tensorflow as tf
from sklearn.model_selection import train_test_split
from numpy import array,asarray,zeros

from nltk.stem import PorterStemmer
from nltk.tokenize import sent_tokenize
import nltk
nltk.download('punkt')

import keras
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences

from keras.models import Sequential
from keras.layers.convolutional import Conv1D,MaxPooling1D
from keras.layers import Dense,Flatten,Embedding,Input,Dropout, GlobalMaxPooling1D
from keras.callbacks import ModelCheckpoint

from gensim.models import Word2Vec
import gensim.downloader as api



# Create a validation set from train set
# Please use random_state of 22 and test_size of 0.1
cnn_bt_train, cnn_bt_val = train_test_split(binary_train, test_size = 0.1, random_state = 22)
print("bt: ",cnn_bt_train.shape)
cnn_bt_train.head(10)

cnn_multi_train, cnn_multi_val = train_test_split(multi_tr, test_size = 0.1, random_state = 22)
print("multi: ",cnn_multi_train.shape)

print(type(cnn_bt_train["text"][0]))
print(cnn_bt_train.head(10))

"""### 1. Randomly Initializing Embedding Matrix"""

#Tokenize the sentences
tokenizer = Tokenizer()

tokenizer.fit_on_texts(list(cnn_bt_train["text"]))
                            
train_seq  = tokenizer.texts_to_sequences(list(cnn_bt_train["text"])) 
val_seq = tokenizer.texts_to_sequences(list(cnn_bt_val["text"]))

#padding to prepare sequences of same length
train_seq_pad  = pad_sequences(train_seq, maxlen=100)
val_seq_pad = pad_sequences(val_seq, maxlen=100)

word_vec_size = 100

words = tokenizer.word_index
print(len(words))

# Create your own word embeddings from scratch and load a pretrained word embeddings
cnn_bt_train_seqs = [x.split(" ") for x in list(cnn_bt_train["text"])]
x = set()
for row in cnn_bt_train_seqs:
  for w in row:
    x.add(w)

n_unique =  len(x)
print("Number of unique words:", n_unique)


embedding_matrix = np.zeros((n_unique, word_vec_size))
for word, i in words.items():
  if i < n_unique:
    embedding_vector = np.random.rand(word_vec_size)*2 - 1
    if embedding_vector is not None:
      embedding_matrix[i] = embedding_vector
#example 
print(embedding_matrix[3])

# You can check https://radimrehurek.com/gensim/models/word2vec.html for training a word embeddings from scratch
num_words = n_unique

"""### Building the Model: Binary"""

def findWordUnique(tr):
  cnn_bt_train_seqs = [x.split(" ") for x in list(tr["text"])]
  x = set()
  for row in cnn_bt_train_seqs:
    for w in row:
      x.add(w)

  return len(x)

def buildBinaryCNNModel(train_seq, tr_labels, val_seq_pad, val_labels , word_count, embed_matrix, vec_size=100, window = 128, kernel = 4, pool = 3, dense = 64, loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'], epoch = 10):
  max_len = max([len(x) for x in train_seq])
  train_seq_pad = pad_sequences(train_seq, vec_size)
 #print(len(train_seq_pad[0]))
  embedding_layer = Embedding(
    word_count+1,
    vec_size,
    weights=[embed_matrix],
    input_length=max_len,
    trainable=False
  )

  #Set up the network with cnn
  input_shape = Input(shape = (len(train_seq_pad[0]),))

  cnn_bt=embedding_layer(input_shape)

  cnn_bt=Conv1D(window,kernel,activation="relu")(cnn_bt)
  cnn_bt=MaxPooling1D(pool)(cnn_bt)

  cnn_bt=Conv1D(window/2,kernel-1,activation="relu")(cnn_bt)
  cnn_bt=MaxPooling1D(pool)(cnn_bt)

  cnn_bt=Conv1D(window/2,kernel-1,activation="relu")(cnn_bt)
  cnn_bt=GlobalMaxPooling1D()(cnn_bt)

  cnn_bt=Dense(dense,activation="relu")(cnn_bt)
  cnn_bt_out = Dense(1, activation="sigmoid")(cnn_bt)

  cnn_bt_model = tf.keras.Model(input_shape, cnn_bt_out)
  cnn_bt_model.compile(
    loss=loss, optimizer=optimizer, metrics=metrics
  )
  print(cnn_bt_model.summary())

  cnn_bt_res = cnn_bt_model.fit(train_seq_pad, tr_labels, validation_data = (val_seq_pad,val_labels) , batch_size = 40, epochs = epoch, verbose = 1)
  models.append(cnn_bt_model)
  return cnn_bt_res

import itertools

######## HYPERPARAMETER TUNING ########

w = [128, 64]
k = [6,4]
d = [64,32]

models = []
props = []
index = 0
max_accs = []
max_accs_val = []

print("***** For randomly initialized embedding matrix (Binary)")
for l in list(itertools.product(*[w,k,d])):
  epoch = 10
  cnn_bt_r = buildBinaryCNNModel(train_seq, cnn_bt_train["label"].values, val_seq_pad, cnn_bt_val["label"].values , len(words), embedding_matrix, epoch = epoch, window = l[0], kernel = l[1], dense = l[2])
  print("window:",l[0],"kernel:",l[1],"hidden-layer:",l[2],sep=" ")
  props.append(l)
  print("train acc:",cnn_bt_r.history["accuracy"][epoch-1])
  max_accs.append(cnn_bt_r.history["accuracy"][epoch-1])
  print("validation acc:",cnn_bt_r.history["val_accuracy"][epoch-1])
  max_accs_val.append(cnn_bt_r.history["val_accuracy"][epoch-1])
  index+=1

#cnn_bt_r = buildBinaryCNNModel(train_seq, cnn_bt_train["label"].values, val_seq_pad, cnn_bt_val["label"].values , len(words), embedding_matrix, epoch = 8)

max_ind=max_accs_val.index(max(max_accs_val))
max_model = models[max_ind]
max_prop = props[max_ind]

print("***********")
print("max train acc:", max(max_accs))
print("validation acc:", max(max_accs_val))
print("max val model properties:", max_prop)
print("***********")

# Predicting test cases - Randomly Initialized Matrix
test_seq_bt  = tokenizer.texts_to_sequences(list(binary_test["text"])) 

test_seq_bt_pad  = pad_sequences(test_seq_bt, maxlen=100)
bt_test_acc = models[max_ind].evaluate(test_seq_bt_pad,binary_test["label"].values)
print("Test accuracy:",bt_test_acc)

"""| **

### Embedding Words with Word2Vec Gimsim
"""

# You can check https://radimrehurek.com/gensim/auto_examples/howtos/run_downloader_api.html and https://github.com/RaRe-Technologies/gensim-data for loading pretrained word embeddings. 
model_w2v = Word2Vec(cnn_bt_train_seqs, size = word_vec_size, window = 10, workers = 10, min_count = 2)
vocs = list(model_w2v.wv.vocab)
print(vocs)
print(len(vocs))

print(model_w2v.wv.most_similar("food"))

num_words = len(vocs)
embedding_matrix_w2v = np.zeros((num_words, word_vec_size))
for word, i in words.items():
  if i < num_words:
    embedding_vector = model_w2v[word]
    if embedding_vector is not None:
      embedding_matrix_w2v[i] = embedding_vector
#example 
print(embedding_matrix_w2v[139])

# find max sequence length
print(cnn_bt_train_seqs[3])
max_seq_len = max([len(x) for x in train_seq])
print(max_seq_len)

# Predicting test cases - Word2Vec
cnn_bt_r_w2v = buildBinaryCNNModel(train_seq, cnn_bt_train["label"].values, val_seq_pad, cnn_bt_val["label"].values , num_words-1, embedding_matrix_w2v, epoch = 12, window = max_prop[0], kernel = max_prop[1], dense = max_prop[2])
print("train acc:",cnn_bt_r_w2v.history["accuracy"][11])
print("validation acc:",cnn_bt_r_w2v.history["val_accuracy"][11])
bt_test_acc_w2v = models[-1].evaluate(test_seq_bt_pad,binary_test["label"].values)
print("Test accuracy:",bt_test_acc_w2v)

"""### Vector Weights from Gimsim Api"""

# Gensim Model Embedding Matrix
import gensim.downloader as api
model_gensim = api.load("glove-wiki-gigaword-100")
embedding_matrix_gensim = np.zeros((len(words), word_vec_size))
for word, i in words.items():
  if i < len(words):
    if word in model_gensim:
      embedding_matrix_gensim[i] = model_gensim[word]

# Predicting test cases - Gensim API
cnn_bt_r_gensim = buildBinaryCNNModel(train_seq, cnn_bt_train["label"].values, val_seq_pad, cnn_bt_val["label"].values , len(words)-1, embedding_matrix_gensim, epoch = 12, window = max_prop[0], kernel = max_prop[1], dense = max_prop[2])
print("train acc:",cnn_bt_r_gensim.history["accuracy"][11])
print("validation acc:",cnn_bt_r_gensim.history["val_accuracy"][11])
bt_test_acc_gensim = models[-1].evaluate(test_seq_bt_pad,binary_test["label"].values)
print("Test accuracy:",bt_test_acc_gensim)

# Prepare your dataset for CNN classifier

# Create Embedding Matrices and Layers

"""### Building the Model: Multi-class"""

#Tokenize the sentences
mTokenizer = Tokenizer()

mTokenizer.fit_on_texts(list(cnn_multi_train["text"]))
                            
train_seq_m  = mTokenizer.texts_to_sequences(list(cnn_multi_train["text"])) 
val_seq_m = mTokenizer.texts_to_sequences(list(cnn_multi_val["text"]))

#find max sequence length
max_seq_len_m = max([len(x) for x in train_seq_m])
word_vec_size = 100
#padding to prepare sequences of same length
train_seq_mpad  = pad_sequences(train_seq_m, maxlen=word_vec_size)
val_seq_mpad = pad_sequences(val_seq_m, maxlen=word_vec_size)



words = mTokenizer.word_index
print(len(words))

#One hot encoding of labels
cnn_multi_tr_labels = cnn_multi_train["label"].values
cnn_multi_tr_labels = tf.keras.utils.to_categorical(cnn_multi_tr_labels, num_classes = 5)

cnn_multi_val_labels = cnn_multi_val["label"].values
cnn_multi_val_labels = tf.keras.utils.to_categorical(cnn_multi_val_labels, num_classes = 5)

cnn_multi_ts_labels = multi_ts["label"].values
cnn_multi_ts_labels = tf.keras.utils.to_categorical(cnn_multi_ts_labels, num_classes = 5)
print(cnn_multi_tr_labels)

def buildMultiCNNModel(train_seq, tr_labels, val_seq_pad, val_labels , word_count, embed_matrix, vec_size=100, window = 128, kernel = 4, pool = 3, dense = 64, loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'], epoch = 10):
  max_len = max([len(x) for x in train_seq])
  train_seq_pad = pad_sequences(train_seq, vec_size)
 #print(len(train_seq_pad[0]))
  embedding_layer = Embedding(
    word_count,
    vec_size,
    weights=[embed_matrix],
    input_length=max_len,
    trainable=False
  )

  #Set up the network with cnn
  input_shape = Input(shape = (len(train_seq_pad[0]),))

  
  cnn_bt=embedding_layer(input_shape)

  cnn_bt=Conv1D(window,kernel,activation="relu")(cnn_bt)
  cnn_bt=MaxPooling1D(pool)(cnn_bt)

  cnn_bt=Conv1D(window/2,kernel-1,activation="relu")(cnn_bt)
  cnn_bt=MaxPooling1D(pool)(cnn_bt)

  cnn_bt=Conv1D(window/2,kernel-1,activation="relu")(cnn_bt)
  cnn_bt=GlobalMaxPooling1D()(cnn_bt)

  cnn_bt=Dense(dense,activation="relu")(cnn_bt)
  cnn_bt_out = Dense(5, activation="softmax")(cnn_bt)

  cnn_bt_model = tf.keras.Model(input_shape, cnn_bt_out)
  cnn_bt_model.compile(
    loss=loss, optimizer=optimizer, metrics=metrics
  )
  [print(i.shape, i.dtype) for i in cnn_bt_model.inputs]
  [print(o.shape, o.dtype) for o in cnn_bt_model.outputs]
  print(cnn_bt_model.output.shape)
  print(type(cnn_bt_model.output))
  print(cnn_bt_model.summary())

  #train_seq_m = np.asarray(train_seq_m)
  #val_seq_mpad = np.asarray(val_seq_mpad)

  cnn_bt_res = cnn_bt_model.fit(train_seq_pad, cnn_multi_tr_labels , validation_data = (val_seq_mpad, cnn_multi_val_labels ), batch_size = 40, epochs = epoch, verbose = 1) 
  models_m.append(cnn_bt_model)
  return cnn_bt_res

# Randomly initialized embedding matrix 
embedding_matrix = np.zeros((len(words), word_vec_size))
for word, i in words.items():
  if i < len(words):
    embedding_vector = np.random.rand(word_vec_size)*2 - 1
    if embedding_vector is not None:
      embedding_matrix[i] = embedding_vector
#example 
print(embedding_matrix[3])

import itertools

######## HYPERPARAMETER TUNING ########
# with w2v matrix

w = [256, 128]
k = [6,4]
d = [64,32]

models_m = []
props_m = []
index = 0
max_accs_m = []
max_accs_val_m = []

print("***** For randomly initialized embedding matrix (Binary)")
for l in list(itertools.product(*[w,k,d])):
  epoch = 10
  cnn_bt_r = buildMultiCNNModel(train_seq_m, cnn_multi_tr_labels, val_seq_mpad, cnn_multi_val_labels, num_words_m, embedding_matrix_w2v_m, vec_size=word_vec_size, epoch = epoch, window = l[0], kernel = l[1], dense = l[2])
  print("window:",l[0],"kernel:",l[1],"hidden-layer:",l[2],sep=" ")
  props_m.append(l)
  print("train acc:",cnn_bt_r.history["accuracy"][epoch-1])
  max_accs_m.append(cnn_bt_r.history["accuracy"][epoch-1])
  print("validation acc:",cnn_bt_r.history["val_accuracy"][epoch-1])
  max_accs_val_m.append(cnn_bt_r.history["val_accuracy"][epoch-1])
  index+=1

max_ind_m=max_accs_val_m.index(max(max_accs_val_m))
max_model_m = models_m[max_ind_m]
max_prop_m = props_m[max_ind_m]

print("***********")
print("max train acc:", max(max_accs_m))
print("validation acc:", max(max_accs_val_m))
print("max val model properties:", max_prop_m)
print("***********")

cnn_multi_train_seqs = [x.split(" ") for x in list(cnn_multi_train["text"])]

model_w2v_m = Word2Vec(cnn_multi_train_seqs, size = word_vec_size, window = 10, workers = 10, min_count = 2)
vocs_m = list(model_w2v_m.wv.vocab)
print(vocs_m)
print(len(vocs_m))

num_words_m = len(vocs_m)
embedding_matrix_w2v_m = np.zeros((num_words_m, word_vec_size))
for word, i in words.items():
  if i < num_words_m:
    embedding_vector = model_w2v_m[word]
    if embedding_vector is not None:
      embedding_matrix_w2v_m[i] = embedding_vector
#example 
print(embedding_matrix_w2v_m.shape)

# Predicting test cases - Word2Vec Matrix

test_seq_multi  = mTokenizer.texts_to_sequences(list(multi_ts["text"])) 

test_seq_multi_pad  = pad_sequences(test_seq_multi, maxlen=word_vec_size)
multi_test_acc = models_m[max_ind_m].evaluate(test_seq_multi_pad,cnn_multi_ts_labels)
print("Test accuracy:",multi_test_acc)

# Predicting test cases - Random Matrix
cnn_multi_r = buildMultiCNNModel(train_seq_m, cnn_multi_tr_labels, val_seq_mpad, cnn_multi_val_labels, num_words_m, embedding_matrix_w2v_m, vec_size=word_vec_size, epoch = 16, window = max_prop_m[0], kernel = max_prop_m[1], dense = max_prop_m[2])
print("train acc:",cnn_multi_r.history["accuracy"][15])
print("validation acc:",cnn_multi_r.history["val_accuracy"][15])
multi_test_acc_r = models_m[-1].evaluate(test_seq_multi_pad,cnn_multi_ts_labels)
print("Test accuracy:",multi_test_acc_r)

# Gensim Model Embedding Matrix
import gensim.downloader as api
model_gensim = api.load("glove-wiki-gigaword-100")
embedding_matrix_gensim = np.zeros((num_words_m, word_vec_size))
for word, i in words.items():
  if i < num_words_m:
    if word in model_gensim:
      embedding_matrix_gensim[i] = model_gensim[word]

# Predicting test cases - Gensim API Matrix
cnn_multi_gen = buildMultiCNNModel(train_seq_m, cnn_multi_tr_labels, val_seq_mpad, cnn_multi_val_labels, num_words_m, embedding_matrix_gensim, vec_size=word_vec_size, epoch = 16, window = max_prop_m[0], kernel = max_prop_m[1], dense = max_prop_m[2])
print("train acc:",cnn_multi_gen.history["accuracy"][15])
print("validation acc:",cnn_multi_gen.history["val_accuracy"][15])
multi_test_acc_gen = models_m[-1].evaluate(test_seq_multi_pad,cnn_multi_ts_labels)
print("Test accuracy:",multi_test_acc_gen)

"""## My Report

In this project we had to perform sentiment analysis and categorize customer reviews based on their positivity towards the place & service, using natural language processing techniques. The data at hand was in the form of texts and the labels were numbered from 1 to 5, based on increasing positivity. 

The training data has a size of 18000 and the test had 2000 reviews. To train our models, we have dropped the reviews with label "3" and merged 1 with 2 and 4 with 5 to downsample the population to 2 classes, labelling them 0 and 1. Basically negative and positive, without neutral comments. For multi classes we have only ordered our labels from 0 to 4 for one hot encoding arrangements and architectural purposes.

The preprocessing phase had 4 main steps: lowering inputs, tokenizing into words, removing stop words and unnecesarry tokens, and then stemming. The same process was applied to both training and test texts. For non-neural models (which are Naive Bayes & Logistic Regression), stratified k-fold validation was used. For CNN models, ten percent (10%) of the training data was splitted and reserved for validation. 

For the non-neural models, grid searching technique was used to find the best accuracy producing hyperparameters. After individual runs for each model type and hyperparameter combination, we have acquired the following results: 


| Label Type | Model Type  | Hyperparameters                               | Accuracy | F1   |
|------------|-------------|-----------------------------------------------|----------|------|
| Binary     | Naive Bayes | min_df=100, ngram_range=(1,3)                 | 0.87     | 0.87 |
| Binary     | Logistic    | min_df=100, ngram_range = (1,2), l1_ratio=0.5 | 0.91     | 0.91 |
| Multi      | Naive Bayes | min_df=100, ngram_range=(1,2)                 | 0.49     | 0.47 |
| Multi      | Logistic    | min_df=100, ngram_range = (1,3), l1_ratio=0.5 | 0.56     | 0.56 |


When compared, logistic regression regression surpasses naive bayes in terms of accuracy for both labeling types. This could be the result of the evaluation algorithm, which utilizes l1 & l2 regularization together.

For the convolutional models, we have utilized 3 different embedding matrices to fill our word embedding layer, to ease the identificaiton of relation between words. First one was randomly initialized with values between -1 and 1. The second one utilized a word corpus that was made from scratch using our own training data with the help of Word2Vec function. The last one was using pretrained models from the Gensim library to match and extract embedding vectors with our tokens in our corpus. These weights were then connected to a convolutional network and a fully connected layer before outputting. The convolutional part was performing a convolution followed by a max pooling layer 3 times, the final one being a global max pooling layer. Then it was connected to a dense network of a varying kernel size. 

The hyperparameter tuning was for the binary labels performed using the randomly initialized embedding matrix and for w2v matrices with multiclass labeling, for equally giving a chance to both methods rather than one. Hyperparameters tried were as follows: window size = [128, 64]
kernel size = [6,4]
dense layer node size = [64,32].

The best model networks were for binary labels: [64, 4, 32]
The best model networks were for multiclass labels: [128, 4, 32]

The best models were run for each type of embedding matrix and it was found that for the binary labelling, the best model was word2vec, followed by random initialization, followed by gensim with accuracies 0.86, 0.84, 0.80 respectively. For multiclass labeling, the order was the same, with 0.49, 0.45, 0.41 respectively. 

These results were heavily influenced by the architecture of our model. Repeated convolution and max pooling of my model perhaps diminished the effects of some certain tokens perhaps because they were coupled with more repeating/significant words based on context. The dense layer size also affected performance heavily because it controlled the amount the model learned and sometimes it could have lead to overfitting to training data. In such a case, dropout layer could have been used.

Binary segmentation was accurate enough for general purpose usage. However, the same cannot be said for multiclass labelling since almost half of the time the test labels were misrepresented. This could be due to the fact that for even a human reader, the labelling of mediocrely positive or negative comments is ambigious in essence. One might not be so sure to label a review as neutral or negative/positive when the comment includes sentiments of both. Since the labels of the test data are also human-error prone, there might not always be obvious mathematical patterns to be learnt by our model. Or perhaps this type of learning isn't well suited for such a multilabelling task. 
"""